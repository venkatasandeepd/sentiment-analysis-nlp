{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coursework 1: Train a Sentiment Analysis Classifier\n",
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/venkatasandeep/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/venkatasandeep/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# load data and take a quick look\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re, string, nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import pos_tag\n",
    "from collections import defaultdict\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Enjoy the opening credits. They're the best th...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Well, the Sci-Fi channel keeps churning these ...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>It takes guts to make a movie on Gandhi in Ind...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>The Nest is really just another 'nature run am...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Waco: Rules of Engagement does a very good job...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               text sentiment\n",
       "0           0  Enjoy the opening credits. They're the best th...       neg\n",
       "1           1  Well, the Sci-Fi channel keeps churning these ...       neg\n",
       "2           2  It takes guts to make a movie on Gandhi in Ind...       pos\n",
       "3           3  The Nest is really just another 'nature run am...       neg\n",
       "4           4  Waco: Rules of Engagement does a very good job...       pos"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data = pd.read_csv('coursework1_train.csv')\n",
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Enjoy the opening credits. They're the best th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Well, the Sci-Fi channel keeps churning these ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>It takes guts to make a movie on Gandhi in Ind...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Nest is really just another 'nature run am...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Waco: Rules of Engagement does a very good job...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  sentiment\n",
       "0  Enjoy the opening credits. They're the best th...          0\n",
       "1  Well, the Sci-Fi channel keeps churning these ...          0\n",
       "2  It takes guts to make a movie on Gandhi in Ind...          1\n",
       "3  The Nest is really just another 'nature run am...          0\n",
       "4  Waco: Rules of Engagement does a very good job...          1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking for null data\n",
    "raw_data.isnull().sum()\n",
    "\n",
    "if('Unnamed: 0' in raw_data.columns):\n",
    "    del raw_data['Unnamed: 0']\n",
    "\n",
    "raw_data.sentiment.value_counts()\n",
    "\n",
    "raw_data['sentiment'] = raw_data.sentiment.map(lambda x: int(1) if x =='pos' else int(0))\n",
    "\n",
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "negate_handle = {\n",
    "\"aren\\'t\" : \"are not\",\n",
    "\"can\\'t\" : \"cannot\",\n",
    "\"couldn\\'t\" : \"could not\",\n",
    "\"didn\\'t\" : \"did not\",\n",
    "\"doesn\\'t\" : \"does not\",\n",
    "\"don\\'t\" : \"do not\",\n",
    "\"hadn\\'t\" : \"had not\",\n",
    "\"hasn\\'t\" : \"has not\",\n",
    "\"haven\\'t\" : \"have not\",\n",
    "\"he\\'d\" : \"he would\",\n",
    "\"he\\'ll\" : \"he will\",\n",
    "\"he\\'s\" : \"he is\",\n",
    "\"i\\'d\" : \"I would\",\n",
    "\"i\\'d\" : \"I had\",\n",
    "\"i\\'ll\" : \"I will\",\n",
    "\"i\\'m\" : \"I am\",\n",
    "\"isn\\'t\" : \"is not\",\n",
    "\"it\\'s\" : \"it is\",\n",
    "\"it\\'ll\":\"it will\",\n",
    "\"i\\'ve\" : \"I have\",\n",
    "\"let\\'s\" : \"let us\",\n",
    "\"mightn\\'t\" : \"might not\",\n",
    "\"mustn\\'t\" : \"must not\",\n",
    "\"shan\\'t\" : \"shall not\",\n",
    "\"she\\'d\" : \"she would\",\n",
    "\"she\\'ll\" : \"she will\",\n",
    "\"she\\'s\" : \"she is\",\n",
    "\"shouldn\\'t\" : \"should not\",\n",
    "\"that\\'s\" : \"that is\",\n",
    "\"there\\'s\" : \"there is\",\n",
    "\"they\\'d\" : \"they would\",\n",
    "\"they\\'ll\" : \"they will\",\n",
    "\"they\\'re\" : \"they are\",\n",
    "\"they\\'ve\" : \"they have\",\n",
    "\"we\\'d\" : \"we would\",\n",
    "\"we\\'re\" : \"we are\",\n",
    "\"weren\\'t\" : \"were not\",\n",
    "\"we\\'ve\" : \"we have\",\n",
    "\"what\\'ll\" : \"what will\",\n",
    "\"what\\'re\" : \"what are\",\n",
    "\"what\\'s\" : \"what is\",\n",
    "\"what\\'ve\" : \"what have\",\n",
    "\"where\\'s\" : \"where is\",\n",
    "\"who\\'d\" : \"who would\",\n",
    "\"who\\'ll\" : \"who will\",\n",
    "\"who\\'re\" : \"who are\",\n",
    "\"who\\'s\" : \"who is\",\n",
    "\"who\\'ve\" : \"who have\",\n",
    "\"won\\'t\" : \"will not\",\n",
    "\"wouldn\\'t\" : \"would not\",\n",
    "\"you\\'d\" : \"you would\",\n",
    "\"you\\'ll\" : \"you will\",\n",
    "\"you\\'re\" : \"you are\",\n",
    "\"you\\'ve\" : \"you have\",\n",
    "\"\\'re\": \" are\",\n",
    "\"wasn\\'t\": \"was not\",\n",
    "\"we\\'ll\":\" will\",\n",
    "\"didn\\'t\": \"did not\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entry num 40000\n",
      "num of pos entries 20000\n",
      "num of neg entries 20000\n"
     ]
    }
   ],
   "source": [
    "# check the size of the data and its class distribution\n",
    "all_text = raw_data['text'].tolist()\n",
    "all_lables = raw_data['sentiment'].tolist()\n",
    "\n",
    "print('entry num', len(all_text))\n",
    "print('num of pos entries', len([l for l in all_lables if l==1]))\n",
    "print('num of neg entries', len([l for l in all_lables if l==0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_text[25]\n",
    "#ratings = [re.findall('(\\d{1,2}[\\/]\\d{1,2})', x) for x in all_text]\n",
    "#print(ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text cleaning and preprocessing:\n",
    "\n",
    "def text_preprocessor(data):\n",
    "    \n",
    "    data = [re.sub(re.compile('<.*?>|&([a-z0-9]+|#[0-9]{1,6}|#x[0-9a-f]{1,6});'), '', line) for line in data]\n",
    "    data = [re.sub(r'[^a-zA-Z\\s]', ' ', line) for line in data]\n",
    "    \n",
    "    # strip whitespace and converting to lower case\n",
    "    lower_data = [line.strip().lower() for line in data]\n",
    "    \n",
    "    # Replace apostrophes with words\n",
    "    processed_data = []\n",
    "    for line in lower_data:\n",
    "        line = line.replace(\"-\", \" \")\n",
    "        ref_words = [negate_handle[word] if word in negate_handle else word for word in line.split()]\n",
    "        processed_data.append(\" \".join(ref_words))\n",
    "        \n",
    "    #remove punctuation\n",
    "    processed_data = [line.translate(str.maketrans('', '', string.punctuation)) for line in processed_data] \n",
    "    \n",
    "    # removing stopwords\n",
    "    stops = set(stopwords.words(\"english\"))\n",
    "    processed_data = [\" \".join([word for word in line.split() if word not in stops]) for line in processed_data]\n",
    "    \n",
    "    return processed_data\n",
    "\n",
    "def stem_lemmatize(data):\n",
    "    # stemming\n",
    "    # stemmer= PorterStemmer()\n",
    "    # processed_data = [\" \".join([stemmer.stem(word) for word in line.split()]) for line in data]\n",
    "    \n",
    "    # lemmatization\n",
    "    lemmatizer=WordNetLemmatizer()\n",
    "    processed_data = [\" \".join([lemmatizer.lemmatize(word) for word in line.split()]) for line in data]\n",
    "    \n",
    "    return processed_data\n",
    " \n",
    "processed_data = text_preprocessor(all_text)\n",
    "processed_data = stem_lemmatize(processed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'enjoy opening credit best thing second rate inoffensive time killer feature passable performance like eric robert martin kove main part however go newcomer tommy lee thomas look bit diminutive kind action nevertheless occasionally manages project banty rooster kind belligerence first time see bare chested sweaty engaged favorite beefcake activity chopping wood seven scene without shirt including one hanged wrist zapped electricity la mel gibson lethal weapon could use better script however since manner expose truth corruption violence inside prison never convincing also talk million dollar apparently tied investigation never explained plus though sending john woodrow undercover john wilson amusing play presidential name co star jody ross nolan show promise inmate early proceeding shown hanged wrist getting punched burly guard one final note movie low budget painfully responsible lack extra despite impressive size prison seems hold inmate note cast credit end helpful record burly bald headed guard us jody nolan punching bag played bill fishback young fair haired guard administers electric shock tommy lee thomas played marc chenail'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data['text'] = processed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import model_selection, naive_bayes, svm\n",
    "from sklearn.metrics import precision_recall_fscore_support,accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report \n",
    "from sklearn.preprocessing import MaxAbsScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text, test_text, train_labels, test_labels = train_test_split(raw_data['text'], raw_data['sentiment'], test_size=0.25, random_state=2908)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf-idf initialization\n",
    "train_vectorizer = TfidfVectorizer(max_features=5000)\n",
    "train_vecs = train_vectorizer.fit_transform(train_text)\n",
    "test_vecs = TfidfVectorizer(max_features=5000,vocabulary=train_vectorizer.vocabulary_).fit_transform(test_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CountVectorizer initialization\n",
    "count_vect = CountVectorizer(max_features=5000)\n",
    "X_train_vectorized = count_vect.fit_transform(train_text)\n",
    "X_test_vectorized = CountVectorizer(max_features=5000,vocabulary=count_vect.vocabulary_).fit_transform(test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 5000)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_vecs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create hyperparameter options\n",
    "\n",
    "log_hyperparameters = dict(C=[0.001, 0.01, 0.1, 1, 10, 100, 1000], penalty=['l1', 'l2'])\n",
    "log_clf = GridSearchCV(LogisticRegression(), log_hyperparameters, cv=10, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Penalty: l2\n",
      "Best C: 1\n",
      "accuracy 0.8849\n",
      "[[4412  623]\n",
      " [ 528 4437]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.88      0.88      5035\n",
      "           1       0.88      0.89      0.89      4965\n",
      "\n",
      "    accuracy                           0.88     10000\n",
      "   macro avg       0.88      0.88      0.88     10000\n",
      "weighted avg       0.89      0.88      0.88     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# training: tf-idf + logistic regression\n",
    "# train model\n",
    "\n",
    "best_model = log_clf.fit(train_vecs, train_labels)\n",
    "best_penalty = best_model.best_estimator_.get_params()['penalty']\n",
    "best_c = best_model.best_estimator_.get_params()['C']\n",
    "print('Best Penalty:', best_penalty)\n",
    "print('Best C:', best_c)\n",
    "\n",
    "best_clf = LogisticRegression(C=1,penalty=best_penalty).fit(train_vecs, train_labels)\n",
    "\n",
    "# test model\n",
    "test_pred = best_clf.predict(test_vecs)\n",
    "\n",
    "acc = accuracy_score(test_labels, test_pred)\n",
    "print('accuracy', acc)\n",
    "\n",
    "# confusion matrix\n",
    "print(confusion_matrix(test_labels, test_pred))\n",
    "\n",
    "# classification_report\n",
    "print(classification_report(test_labels, test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Penalty: l2\n",
      "Best C: 1\n",
      "accuracy 0.8663\n",
      "[[4367  668]\n",
      " [ 669 4296]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.87      0.87      5035\n",
      "           1       0.87      0.87      0.87      4965\n",
      "\n",
      "    accuracy                           0.87     10000\n",
      "   macro avg       0.87      0.87      0.87     10000\n",
      "weighted avg       0.87      0.87      0.87     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# training: CountVectorizer + logistic regression\n",
    "# train model\n",
    "\n",
    "best_model = log_clf.fit(train_vecs, train_labels)\n",
    "best_penalty = best_model.best_estimator_.get_params()['penalty']\n",
    "best_c = best_model.best_estimator_.get_params()['C']\n",
    "print('Best Penalty:', best_penalty)\n",
    "print('Best C:', best_c)\n",
    "\n",
    "clf = LogisticRegression(C=best_c,penalty=best_penalty).fit(X_train_vectorized, train_labels)\n",
    "\n",
    "# test model\n",
    "test_pred = clf.predict(X_test_vectorized)\n",
    "acc = accuracy_score(test_labels, test_pred)\n",
    "print('accuracy', acc)\n",
    "\n",
    "# confusion matrix\n",
    "print(confusion_matrix(test_labels, test_pred))\n",
    "\n",
    "# classification_report\n",
    "print(classification_report(test_labels, test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.8549\n",
      "[[4294  741]\n",
      " [ 710 4255]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.85      0.86      5035\n",
      "           1       0.85      0.86      0.85      4965\n",
      "\n",
      "    accuracy                           0.85     10000\n",
      "   macro avg       0.85      0.85      0.85     10000\n",
      "weighted avg       0.85      0.85      0.85     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# training: tf-idf + Naive Bayes\n",
    "# train model\n",
    "\n",
    "clf = naive_bayes.MultinomialNB()\n",
    "clf.fit(train_vecs, train_labels)\n",
    "\n",
    "# test model\n",
    "test_pred = clf.predict(test_vecs)\n",
    "acc = accuracy_score(test_labels, test_pred)\n",
    "print('accuracy', acc)\n",
    "\n",
    "# confusion matrix\n",
    "print(confusion_matrix(test_labels, test_pred))\n",
    "\n",
    "# classification_report\n",
    "print(classification_report(test_labels, test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.8491\n",
      "[[4318  717]\n",
      " [ 792 4173]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.86      0.85      5035\n",
      "           1       0.85      0.84      0.85      4965\n",
      "\n",
      "    accuracy                           0.85     10000\n",
      "   macro avg       0.85      0.85      0.85     10000\n",
      "weighted avg       0.85      0.85      0.85     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# training: CountVectorizer + Naive Bayes\n",
    "# train model\n",
    "\n",
    "clf = naive_bayes.MultinomialNB()\n",
    "clf.fit(X_train_vectorized, train_labels)\n",
    "\n",
    "# test model\n",
    "test_pred = clf.predict(X_test_vectorized)\n",
    "acc = accuracy_score(test_labels, test_pred)\n",
    "print('accuracy', acc)\n",
    "\n",
    "# confusion matrix\n",
    "print(confusion_matrix(test_labels, test_pred))\n",
    "\n",
    "# classification_report\n",
    "print(classification_report(test_labels, test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SAVE YOUR TRAINED MODEL\n",
    "After you have found the best model, save your trained model and other necessary components (e.g. vocabulary, vectorizer) to a file. I will load your model from the saved file and apply your trained model on some held-out test data. **At submission time, you are supposed to submit the saved model file, and I will NOT re-run your code to train your model; instead, I will directly use your trained model to run test (see notebook *cw1-test.ipybn*)**. \n",
    "\n",
    "Below is a sample code for saving the model (and other necessary components) obtained above, using the *pickle* package in Python. *You should adjust the code to save the necessary components for re-running your model!*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# save model and other necessary modules\n",
    "all_info_want_to_save = {\n",
    "    'model': best_clf,\n",
    "    'vectorizer': TfidfVectorizer(max_features=5000,vocabulary=train_vectorizer.vocabulary_),\n",
    "    'negate_handle' : negate_handle,\n",
    "    #'text_preprocessor' : text_preprocessor(test_text)\n",
    "}\n",
    "with open(\"sample_trained_model.pickle\", \"wb\") as f:\n",
    "    pickle.dump(all_info_want_to_save, f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In *cw1-test.ipynb*, I provide a sample code to illustrate how to re-load your saved model and apply it to some test data. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
